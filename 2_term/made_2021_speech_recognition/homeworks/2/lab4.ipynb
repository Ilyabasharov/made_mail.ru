{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> Практические задания по цифровой обработке сигналов </center>\n",
    "# <center> Четвертая лабораторная работа </center>\n",
    "# <center> Акустические признаки </center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "import scipy \n",
    "import scipy.fft\n",
    "import IPython.display as ipd\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa.display\n",
    "import librosa.filters\n",
    "import hashlib\n",
    "from glob import glob\n",
    "import os\n",
    "import sklearn\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция отрисовки аудио сигнала. \n",
    "def draw_waveform(wav, sr, figsize=(14, 5)):\n",
    "    # Отрисовка звукового сигнала во временной области\n",
    "    plt.figure(figsize=figsize)\n",
    "    librosa.display.waveplot(wav, sr=sr)\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Для выполнения задания нам понадобится датасет yes/no. \n",
    "# Про датасет можно почитать тут https://www.openslr.org/1/\n",
    "\n",
    "# Скачаем его\n",
    "![ ! -f  waves_yesno.tar.gz ] && wget https://www.openslr.org/resources/1/waves_yesno.tar.gz\n",
    "# И распакуем\n",
    "!tar -xvzf waves_yesno.tar.gz\n",
    "\n",
    "# P.S если у вас Windows, или по каким-либо еще причинам данные не скачались, \n",
    "# то их можно скачать руками отсюда: https://www.openslr.org/1/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загрузим один из файлов\n",
    "wav, sr = librosa.load(\"waves_yesno/0_1_0_1_1_1_0_0.wav\")\n",
    "draw_waveform(wav, sr)\n",
    "ipd.Audio(wav, rate=sr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как можно услышать, в этом датасете произносятся какие-то два слова (yes/no на иврите). Каждый файл состоит из 8 произнесений. Метки слов указаны в названиях файлов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Построим спектрограмму загруженной вавки\n",
    "stft = librosa.stft(wav)\n",
    "stft_db = librosa.amplitude_to_db(abs(stft))\n",
    "plt.figure(figsize=(15,10))\n",
    "librosa.display.specshow(stft_db, sr=sr, x_axis='time', y_axis='hz')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задание 0.1: Анализ спектрограммы (0.5 балла)\n",
    "1. Посмотрите на спектрограмму и попробуйте найти признаки, по которым можно отличить произнесение \"yes\" от \"no\". \n",
    "1. В каких частотах находится основная энергия этого речевого сигнала? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. -\n",
    "2. -"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задание 1: Мел-шкала (1 балл)\n",
    "Нарисовать спектрограму в [mel-шкале](https://en.wikipedia.org/wiki/Mel_scale). \n",
    "Использовать формулу, представленную Дугласом О'Шонесси."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mel(f):\n",
    "    # YOUR CODE HERE\n",
    "    #\n",
    "    \n",
    "    #\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_mel():\n",
    "    x = np.random.randint(100, size=(1000, 100))\n",
    "    x_mel = mel(x)\n",
    "    x_hz = 700.0 * (10.0 ** (x_mel / 2595.0) - 1.0)\n",
    "    assert np.allclose(x, x_hz), \"TEST Hertz -> Mel -> Hertz  failed. \"\n",
    "    print(\"Ok!\")\n",
    "test_mel() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Мел-фильтры\n",
    "Одними из наиболее популярных акустических признаков являются Filter Banks (fbanks). \n",
    "fbanks вычисляются применением нескольких (количество фильтров = количество fbanks) треугольных фильтров к мел-спектрограмме. Чтобы не делать два действия со спектрограммой, переход к мел-шкале и применение фильтров в мел-шкале можно заменить на перевод мел-фильтров в Герц-шкалу и применение их к Герц-спектрограмме.\n",
    "\n",
    "\n",
    "\n",
    "# Задание 2 (3 балла)\n",
    "Реализуйте функцию вычисления fbank. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mel_filters(sr, n_fft, n_mels):\n",
    "    # функция построения треугольных мел-фильтров в герц-шкале\n",
    "    # sr - sample rate\n",
    "    # n_fft - length of the FFT window \n",
    "    # n_mels - number of filters\n",
    "    # return mel filters matrix. [n_mel, n_fft]\n",
    "\n",
    "    # YOUR CODE HERE\n",
    "    #\n",
    "    \n",
    "    #\n",
    "    raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert mel_filters(32, 46, 4).shape == (4, 24) and \\\n",
    "    mel_filters(65, 45, 5).shape == (5, 23), \"Wrong shape\"\n",
    "assert np.allclose(mel_filters(16, 8, 4), librosa.filters.mel(16, 8, n_mels=4, htk=True))\n",
    "assert np.allclose(mel_filters(8600, 512, 40), librosa.filters.mel(8600, 512, n_mels=40, htk=True))\n",
    "print(\"All ok!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fbanks(wav: np.ndarray, sr: int, window_ms=25, step_mc=10, n_fbanks=40):\n",
    "    # wav - input signal\n",
    "    # sr - sample rate\n",
    "    # window_ms - window length in milliseconds\n",
    "    # step_ms - stft step in milliseconds\n",
    "    # n_fbanks - number of filters\n",
    "    # return fbank matrix [n_fbanks, time]\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "        \n",
    "    #\n",
    "    raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_fbank(wav, sr, window_ms=25, step_mc=10, n_fbanks=40):\n",
    "    n_fft = window_ms * sr//1000\n",
    "    hop_length = step_mc * sr//1000\n",
    "    fbanks_lib = librosa.feature.melspectrogram(wav, sr, n_fft=n_fft, hop_length=hop_length, n_mels=n_fbanks, htk=True)\n",
    "    fbanks = get_fbanks(wav, sr, window_ms=window_ms, step_mc=step_mc, n_fbanks=n_fbanks)\n",
    "    \n",
    "    if fbanks_lib.shape != fbanks.shape:\n",
    "        print(\"TEST FAILED\")\n",
    "        print(f\"Shape {fbanks_lib.shape} != {fbanks.shape}\")\n",
    "    if not np.allclose(fbanks_lib, fbanks):\n",
    "        print(\"TEST FAILED\")\n",
    "        print(f\"Average diff is {np.mean(np.abs(fbanks_lib - fbanks))}\")\n",
    "        return -1\n",
    "    print(\"TEST PASSED\")\n",
    "    return 0\n",
    "    assert test_fbank(wav[:sr*1], sr) == 0, \"1 sec wav test failed\"\n",
    "    assert test_fbank(wav, sr) == 0 , \"All wav test failed\"\n",
    "    print(\"All ok!\")\n",
    "test_fbank(wav, sr, window_ms=25, step_mc=10, n_fbanks=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fbanks = get_fbanks(wav, sr)\n",
    "plt.figure(figsize=(15,10))\n",
    "librosa.display.specshow(fbanks, sr=sr, x_axis='time')\n",
    "plt.ylabel(\"Filter number\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задание 3 (3 балла)\n",
    "Реализовать вычисление [mfcc](https://en.wikipedia.org/wiki/Mel-frequency_cepstrum)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mfcc(wav: np.ndarray, sr: int, window_ms=25, step_mc=10, n_mfcc=13):\n",
    "      # wav - input signal\n",
    "    # sr - sample rate\n",
    "    # window_ms - window length in milliseconds\n",
    "    # step_ms - stft step in milliseconds\n",
    "    # n_mfcc - number of filters\n",
    "    # return mfcc matrix [n_mfcc, time]\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "   \n",
    "    #\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_mfcc(wav, sr, window_ms=25, step_mc=10, n_mfcc=13):\n",
    "    n_fft = window_ms * sr//1000\n",
    "    hop_length = step_mc * sr//1000\n",
    "    mfcc_lib = librosa.feature.mfcc(wav, sr, n_fft=n_fft, hop_length=hop_length, n_mfcc=n_mfcc, n_mels = 40, htk=True)\n",
    "    mfcc = get_mfcc(wav, sr, window_ms=window_ms, step_mc=step_mc, n_mfcc=n_mfcc)\n",
    "    \n",
    "    if mfcc_lib.shape != mfcc.shape:\n",
    "        print(\"TEST FAILED\")\n",
    "        print(f\"Shape {mfcc_lib.shape} != {mfcc.shape}\")\n",
    "    if not np.allclose(mfcc_lib, mfcc, atol=1e-04):\n",
    "        print(\"TEST FAILED\")\n",
    "        print(f\"Average diff is {np.mean(np.abs(mfcc_lib - mfcc))}\")\n",
    "        return -1\n",
    "    print(\"TEST PASSED\")\n",
    "    return 0\n",
    "assert test_mfcc(wav[:sr*1], sr) == 0, \"1 sec wav test failed\"\n",
    "assert test_mfcc(wav, sr) == 0 , \"All wav test failed\"\n",
    "print(\"All ok!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mfcc = get_mfcc(wav, sr)\n",
    "plt.figure(figsize=(15,10))\n",
    "librosa.display.specshow(mfcc, sr=sr, x_axis='time')\n",
    "plt.ylabel(\"Filter number\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Классификация слов\n",
    "Построим простую систему, классифицирующую слова yes/no."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загрузим весь датасет"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_yn_dataset(directory):\n",
    "    X, labels = [], []\n",
    "    for f in glob(directory +\"/*.wav\"):\n",
    "        name = os.path.basename(f)[:-4]\n",
    "        y = [int(l) for l in name.split(\"_\")]\n",
    "        x, _ = librosa.load(f)\n",
    "        X.append(x)\n",
    "        labels.append(y)\n",
    "        \n",
    "    return X, labels\n",
    "        \n",
    "X, Y = load_yn_dataset(\"waves_yesno/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Отделим 20% для теста"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = sklearn.model_selection.train_test_split(X, Y,test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задание *4 (1 балл)\n",
    "Voice Activity Detector (VAD) определяет, есть ли речь в текущем кадре или нет.\n",
    "Реализуйте простой VAD.\n",
    "Настройте VAD, чтобы хорошо определялись границы слов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "\n",
    "# train_VA = # np.ndarray. 1 - Voice, 0 - silence\n",
    "# test_VA = # np.ndarray. 1 - Voice, 0 - silence\n",
    "        \n",
    "#\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_VAD(VA, Y):\n",
    "    def check_diff(diff, num_words):\n",
    "        if diff.sum()!=0:\n",
    "            print(\"VAD detected speech at the beginning (or end) of audio\")\n",
    "            return -1 \n",
    "        if not (diff > 0).sum() == (diff > 0).sum() ==  num_words:\n",
    "            print(\"Wrong number of words. Each audio contains 8 words\")\n",
    "            return -2\n",
    "        return 0\n",
    "    \n",
    "    for i, (va, y) in enumerate(zip(VA, Y)):\n",
    "        diff = va[1:]  - va[:-1]\n",
    "        assert check_diff(diff, len(y)) == 0, f\"Bad {i} example\"\n",
    "\n",
    "test_VAD(train_VA, Y_train)\n",
    "test_VAD(test_VA, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задание *5 (2 балла)\n",
    "Обучите классификатор, определяющий, какое слово было сказано. Используйте VAD для разбиения входных файлов на отдельные слова. Классификацию можно сделать, например, с помощью SVM по усредненным признаки слов выделеных слов. Или любым другим удобным для вас способом. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
